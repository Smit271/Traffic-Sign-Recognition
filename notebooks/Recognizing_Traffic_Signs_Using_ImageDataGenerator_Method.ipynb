{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Dn6Sl3suTg5"
   },
   "source": [
    "# Recongizing Traffic Signs usign CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDF4-xGeuZWQ"
   },
   "source": [
    "## Installing kaggle CLI \n",
    "- To download data into our google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "-Ltj5ff4Oeap",
    "outputId": "18087d63-8ce3-4af9-d67e-c5be95ca1a50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 881 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /home/smit/.local/lib/python3.8/site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: certifi in /home/smit/.local/lib/python3.8/site-packages (from kaggle) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil in /usr/lib/python3/dist-packages (from kaggle) (2.7.3)\n",
      "Requirement already satisfied: requests in /home/smit/.local/lib/python3.8/site-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: tqdm in /home/smit/.local/lib/python3.8/site-packages (from kaggle) (4.57.0)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
      "Requirement already satisfied: urllib3 in /home/smit/.local/lib/python3.8/site-packages (from kaggle) (1.26.4)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 769 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /home/smit/.local/lib/python3.8/site-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/smit/.local/lib/python3.8/site-packages (from requests->kaggle) (4.0.0)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73053 sha256=736b50f834c539b496449de16f7c69396d57d445937b7bd9f8007ecc56bce307\n",
      "  Stored in directory: /home/smit/.cache/pip/wheels/29/da/11/144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.12 python-slugify-5.0.2 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "T4ozaNQROiMa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/Smit/kaggle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Y3CQVbpuhyj"
   },
   "source": [
    "Going to Kaggle folder to download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "DurHoxDzOsXA",
    "outputId": "d09fe688-41e5-4a80-8289-087e702bb4f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/drive/MyDrive/Smit/kaggle'\n",
      "/home/smit/Smit/Projects/012_Traffic_Signal_Classifier_Mini_Project\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/Smit/kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxjODpuIum1c"
   },
   "source": [
    "So let's download data with kaggle command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "H9w6qV6dPCr9",
    "outputId": "43c398ea-9c55-423a-8714-f1e0ed603f30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/home/smit/.local/bin/kaggle\", line 5, in <module>\r\n",
      "    from kaggle.cli import main\r\n",
      "  File \"/home/smit/.local/lib/python3.8/site-packages/kaggle/__init__.py\", line 19, in <module>\r\n",
      "    from kaggle.api.kaggle_api_extended import KaggleApi\r\n",
      "  File \"/home/smit/.local/lib/python3.8/site-packages/kaggle/api/__init__.py\", line 22, in <module>\r\n",
      "    from kaggle.api.kaggle_api_extended import KaggleApi\r\n",
      "  File \"/home/smit/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py\", line 84, in <module>\r\n",
      "    class KaggleApi(KaggleApi):\r\n",
      "  File \"/home/smit/.local/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py\", line 102, in KaggleApi\r\n",
      "    os.makedirs(config_dir)\r\n",
      "  File \"/usr/lib/python3.8/os.py\", line 213, in makedirs\r\n",
      "    makedirs(head, exist_ok=exist_ok)\r\n",
      "  File \"/usr/lib/python3.8/os.py\", line 213, in makedirs\r\n",
      "    makedirs(head, exist_ok=exist_ok)\r\n",
      "  File \"/usr/lib/python3.8/os.py\", line 213, in makedirs\r\n",
      "    makedirs(head, exist_ok=exist_ok)\r\n",
      "  [Previous line repeated 1 more time]\r\n",
      "  File \"/usr/lib/python3.8/os.py\", line 223, in makedirs\r\n",
      "    mkdir(name, mode)\r\n",
      "PermissionError: [Errno 13] Permission denied: '/content'\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oh03GQdjur5H"
   },
   "source": [
    "Unzipping data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w2iJVQUoPIl5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open *.zip, *.zip.zip or *.zip.ZIP.\r\n",
      "\r\n",
      "No zipfiles found.\r\n"
     ]
    }
   ],
   "source": [
    "!unzip \\*.zip  && rm *.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "2-P2mbtjPMNq",
    "outputId": "eea922c7-1db7-429d-b019-028352b6e711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/smit/Smit/Projects/012_Traffic_Signal_Classifier_Mini_Project\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1123ynKEuvVl"
   },
   "source": [
    "## Installing tensorflow-gpu \n",
    "- for better effeciency and faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "yqc3Y2xDPuSS",
    "outputId": "d707f78b-905b-46d9-9212-042fb13c2cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.5.0-cp38-cp38-manylinux2010_x86_64.whl (454.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 454.4 MB 24 bytes/s a 0:00:01    |██████▌                         | 92.5 MB 3.5 MB/s eta 0:01:44MB 430 kB/s eta 0:05:10\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /home/smit/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/smit/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/smit/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.12)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/smit/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/smit/.local/lib/python3.8/site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/smit/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp38-cp38-manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 47 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /home/smit/.local/lib/python3.8/site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard~=2.5\n",
      "  Using cached tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 49 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /home/smit/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.19.5)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/smit/.local/lib/python3.8/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/smit/.local/lib/python3.8/site-packages (from tensorflow-gpu) (0.36.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/smit/.local/lib/python3.8/site-packages (from tensorflow-gpu) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/smit/.local/lib/python3.8/site-packages (from tensorflow-gpu) (3.7.4.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/smit/.local/lib/python3.8/site-packages (from tensorflow-gpu) (3.15.6)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow-gpu) (54.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/smit/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow-gpu) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/smit/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow-gpu) (0.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/smit/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow-gpu) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/smit/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow-gpu) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/smit/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow-gpu) (1.27.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/smit/.local/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow-gpu) (1.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/smit/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/smit/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/smit/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/smit/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/smit/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/smit/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/smit/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/smit/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/smit/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-gpu) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-gpu) (3.1.0)\n",
      "Installing collected packages: tensorboard-data-server, grpcio, tensorflow-estimator, tensorboard, keras-nightly, h5py, gast, tensorflow-gpu\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.32.0\n",
      "    Uninstalling grpcio-1.32.0:\n",
      "      Successfully uninstalled grpcio-1.32.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.4.1\n",
      "    Uninstalling tensorboard-2.4.1:\n",
      "      Successfully uninstalled tensorboard-2.4.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.1 requires gast==0.3.3, but you have gast 0.4.0 which is incompatible.\n",
      "tensorflow 2.4.1 requires grpcio~=1.32.0, but you have grpcio 1.34.1 which is incompatible.\n",
      "tensorflow 2.4.1 requires h5py~=2.10.0, but you have h5py 3.1.0 which is incompatible.\n",
      "tensorflow 2.4.1 requires tensorflow-estimator<2.5.0,>=2.4.0, but you have tensorflow-estimator 2.5.0 which is incompatible.\u001b[0m\n",
      "Successfully installed gast-0.4.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorflow-estimator-2.5.0 tensorflow-gpu-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMG2DwBSu5IH"
   },
   "source": [
    "Let's check which GPU is allocated to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "JFxFStPxUPBs",
    "outputId": "3b598ef5-0e0f-4fb2-d18e-e18a0c2a5368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 26 16:46:16 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.80       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce MX150       Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   49C    P8    N/A /  N/A |      2MiB /  4042MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iBnqTRp0FOe"
   },
   "source": [
    "## About Dataset and its structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2__rsBd40V5t"
   },
   "source": [
    "- I took this dataset from kaggle but this dataset official name is GTSRB - German Traffic Sign Recognition Benchmark, which had been rolled out by Germany.\n",
    "- This Dataset contains 43 types of traffic signs.\n",
    "- Structure of data folder\n",
    "\n",
    "\n",
    "![directory_structure.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAARYAAADPCAYAAAAwC/4cAAAABHNCSVQICAgIfAhkiAAAABl0RVh0U29mdHdhcmUAZ25vbWUtc2NyZWVuc2hvdO8Dvz4AACAASURBVHic7d15WFTl+8fxN8Mu4p4IiopLaC5gCe6SS5r7gpYLoKmoP1zAzEhx31ekcjcTc/dbarllZqkYaaIh7iwCrrgiJrIMyO8PcnIUdEYPgsP9ui6uyznnmWfuM+jHM2dm7scoKysrKyo6ni7dBiCEEEpQ5XcBQgjDI8EihFCcBIsQQnESLEIIxUmwCCEUJ8EihFCcBIsQQnESLEIIxUmwCCEUJ8EihFCcBIsQQnESLEIIxUmwCCEUJ8EihFCcBIsQQnESLEIIxUmwCCEUJ8EihFCcBIsQQnESLEIIxUmwCCEUJ8EihFCcBIsQQnESLEIIxUmwCCEUJ8EihFCcBIsQQnESLEIIxUmwCCEUJ8EihFCcBIsQQnESLE/55JOP2bxl6Wt/XE+vHmzb9m2O+/KrpjdV4MJJfDKgV36XUaiZ5HcBBU3oH2HcvnU3v8vQUtBq8vHpR+NG9fHwHJHfpTzDzs6Gek51mDN7SX6XUqhJsDzlQmQMFyJj8rsMLQWxpoKqY6cP+CssnBs3buV3KYXaGxssPj79cHFxJjU1lWpVHQgJOYpNubd4u3oVDv9xjClTFmjG9uzZiY4dW2Nna0Ni0j327Qvh21Ubycx8BEDNWtVZsWyuZvw/Dx7Qvp2n1uNVq1aZ1asXMnL4ePp6uFPHqSZJSUms/e4HduzYp3f9LVs1YehQT4oXteb0mUhu3b6jtV+XmgBMTU357bctTJm6kBo1qtGmTXOKWhVh2fK1bNm8QzPu/RaN8R7YB1u7siTcuE1w8BZ+2XtAa65adRwZOXwgVatUIjHpHr8f+JPV324i5WEqADNm+tO8WUPN+JCQbQA8TE6h7Yd9NNuLFC3CiGGf4PZ+Q0yNTYmIOMfCoOVcuZKg9XhLl87m/IVoYuMv0/ujrtiUK0NoaBjjA+bwyYBe9O7dhR7u3ty//0Bzn+bNGzJjhj/e3mM4fz5aaz5jYxXtPmzJggXLnvvci7z3xgYLgKWlBb6+E2jXoTXDffrxfz5jSU9NZ9W3C9i0cTsXImPo0qUtgwb2Ztr0IC5ExlC9amXGjfNFna4mOHgLABdj4vHyGglAu/Yt6dixda6POdx3AKu/3cyy5d/R9sMWfPbZUM6cieTixXid63ZxcWLypNFs3Lid3/b/QXn7cvh/5sPD1DTNGH1qAvDzG8SJExEsW/IdANHRcZp97Tq0ZPiw/gQGriAy6iJ1677DmNFDyczMZP+vIQA4vl2VRV/O4Putu5g7dwml3yrJKN/BlClViqlTAwGYMiUQYyNjvIf0pYHruwwaOPqZOoyMjFi4YDImpsYEjJ1DcloKHn26sWLlPPr2GU5iYpLW+A8+aM716zfZtGk7yQ9TeJj8EICtP+yiV68udOrchvXrtmrGd+n6IX+Hn34mVACaNHWFrCz+/DPsuc+VyHtvdLDcvn2X+/cfcDnuMgAXzseQmZkJQOnSJQD46+jfnAg/xeX4awDcunmHgyFHcHFx1gRLWmo6sbHZc9y5fe+5j7noq9X8HX4agJjFwXTt3BYnp3f0CpZevbtxLCyCpUuzQ+BCZAyVKtvTuWMbzRh9agIIDT3GzBlfP7Pd1MSE4cP6s2zJWvb/ehiAy/HXqOJQkY96dtIEi4dXdyJOnWXxotXZxxYTR2DWcj7p9zEqlYpHjx6RnqYG1GSoM8h69IiU1NRnHq9pU1dq1KhKnz4+XL16A4CpUxayaeNSevftxpJFwVrj791NYtiwsf/O/Z+kpH/YsWMf7t3as3nTj2RkZGJfwRaX+nX5wn9Gjs9B545t2LVnv+ZMVOSfNzpYdHE94Sbde7Rn/Dg/7MrbYKIyxtzCjNh/w0hfD1Mfav6clZXFP/88oESJYnrN4VCpAj/u2Ku1LUOd8VL1PPb38dM5bq9c2Z5i1taMHj2UTz8dotmuMjbiYXKK5na1qlXYt/+Q1n2PHQ3n2NFwveqo7liFhBs3NaECkJGRyclTZ6lTy/GZ8WfORj4TKo9t2fIT3bu3w+39xuz/NYROXdsSH3+F0D+PPzPWtlxZ6td3YkHgcr3qFXnD4IPFq19Pundrz/TpC4k4dY70NDV+ft7UqVtDkfmzsrJe6j4vcbeXYmKa/SueO3cx585HPVXHf382Mnq5Y8lJVg4nDI8y9Z/75o3b7PvlEL0+7szhw0fp0L4li5esyXFsh06tOX48guvXb+S4X7xeBv85lqZNXPgj9BhhYRGa/xnNzc3ytaaY2EvUrV1Ta5upmWmePFbcpSukpabjULUSsbGXNT9XLl/n2vX/LqZGRcdSt4522Fav5oCfnzcmJsZa29PS1bk+h9FRsZSzKYutrY1mm7GxirpONTh7LirH+zzP+o1bcXSsyshhA0hPVbPv54PPjDE2VtGhXSt+2vmL3vOLvGHwwRIZeRFXVyeqVatM8RLWdOnSlrZt3TAz/e8fspm5KfaV7LCvZEfJksUwRqW5XapUCcVr2rhpO64NnPEe3Jfq1Rxo2aoJH/fopDVGqZpSklP4ZvVGerp3xKtfT+zt7ahZqzoLgiYzcsRAzbh1677HuW5tBgzqTYUK5ahdtwbjAkZSukxJMjIyteaMvBBDOduydOraBvtKdtR7tw7mFtlBE3LoKFHRF5k69TNq1qpOJYcKfPHFCIoXtWbDhm16P1eX4q5yKOQonbu25futu1BnPPuSsXFjF1QmKv44/Jfe84u8YfAvhZYuXYuFpTlffjUVE5UJYSdOsnfvQVq3aoapiQnqjAyqVqus9dYuwIZ1iwH44YfdBAWtVLSmv4+fYtLk+fj49KNH9w6cPR/Jjz/t5YMP3DRjlKxp04btJN69h2dfd/r3/4ikxPv8fjCUld9s0Iy5cP4iw30D8B0xkL69unH3biL7fztM8Jotz8wXEnKUdet+YIi3B1aWRbhy9RpjxkwnIeEmWVlZjPKbzPARn7Bg/sTst5tPn8d7yOfcuZ2o71MFwKFDR3F5z4kft+3NcX+nzm3YvWv/MwEo8o9RVlZWVlR0PF26DcjvWt54xYtbs2VzzhcPL8bG83//N/Y1V2QYVq6cx8mIcyz6+tmvPKhUKjy93Pl5zwH5UFwBIsGiICMjI+zsyua4T52Ryc0bt19zRW+2t6tXoUOn1rRp3RyPfiO5U4C+1iCez+BfCr1OWVlZWm+zipdnaWXJ4sUzuXYtgTFfTJdQecNIsIgCKSU5hQ/ayDeU31QG/66QEOL1k2ARQihOgkUIoTgJFiGE4iRYhBCKk2ARQihOgkUIoTgJFoXNmzuBkJBtmp8ePTrmd0l5ytOrB199PS2/yxAFjHxATmELApdjaWkOwIrl8/K5mrzXsWMrVqzY8OKBolCRYFFYQsJNzZ8fPTLsFokurk5YWVkREnIkv0sRBYwEix5MTU3xHtyHtm3fx8LMnKjoWFat3sTfx0/pPdeLVg4AqORQgSGDPahTpyYqlRFnT0exYsU6oqJjNWOKFC3CkMEeNGlUH+vi1lyKv8K69Vs5eODPPKnpSZ07t+Hnnw/k2lpSFF5yjUUPkyZ/iptbQ+bMXsyQof6cOXOB+XMmUKVKJb3mebxywMqV6+njMYygwJV06dQWT88emjEqlYrAeZPIzHyEn+8k/EZOQp2pJjBoMpZWlppxn302lHrOtZk2LYhB3qMJPXKcaVPHUFvP1pu61PSkUqVK0KSJK7t26r/0iTB8csaioypVKuLWvCEjho8n/OQZAJYu/Q678uWoWau6Xl36dVk5wNrairI2ZViy7DtiYuIAmDNnMS1bNMXCzIyUfxthV61ckYiIs5yMOAvA6lWbuH3zDukp6Xodny41Pald+5acOxulWUlAiCdJsOioajUHHj16xKnT57S2Txg/N5d75E6XlQOSkv5h1aqN+Pv70K5tC8IjznDsaDjbtu3Rmmv58rWMG++Lo2NVTpw4RdiJCHbt2q/39R19VzPo1PED1uQQOEKABIvOjIyMFJtL15UDgoO3sGPnPlwb1KP+e3Xx7NOdsL8jmDRxvqYNY+ifx+npPhgXV2fefbcO/p/5kJaWzqjRk/VqLKXPagb169eleDFrfj8Y+mpPhDBYBnONRaV68aHoMgZyDpGY6DhUKhW13tFeG8fD052mTV11K/Jfuqwc4Ph2VQYP8eT+vX/Ys+s3pk0NYqjPFzRv1pC6zrUAKGplxeAhnpSxKcWhQ0cIClpJ7z7DsLS0oFOnNs887qvW9Finzm3Y+8tBUlPSctwvhEEEy/stGvP77//Dw9M91zG25cqyZ9daFgROfu5cwasXsv3HbylqZaW1PSYmjkMhR/D/Yjj1nGtTrlxZPDzd6e/1ETfv/Lfu8ltlS2u66RsZG1GqdAnN7cfBpsvKAQ+SH+Du3h7fUd7YV7LDzs6Glq2akZ6m5tq/ayA/SE6maRMXxvqPoGbN6pS1KUOz5q4UK2ZNXNwlvZ5DXWoCKFmyOM2aNXip9apF4WEQL4UyMzJJS09Hrc79bc9HWVmkZahJS3t2WdAnpaWrSU9PJ6fltSZPCsR7cB8mTx2NhYUFFyJjGD16CpHnYjRjPv/Mh4aN3tXc9vRwx9MjO/A6dvQiKekfnVYOuHr1Bn6+Exk0sA9LF83G1MSY6IvxjPliutZnZUaNnszgQX2ZMd2fYsWsuZ5wg8VLgjXLqepKl5oAPmzfksgLFzUXlIXIiTTTNnBKrxzQrkNLrl+5oXlnTIicSLAYOFk5QOQHg3gpJHInKweI/GAQF2+FEAWLBIsQQnESLEIIxUmwCCEUJ8EihFCcBIsQQnESLEIIxUmwCCEUJ8FSiBS1smLHzjW079gqv0vJE7a2NrRv11KRuXyG9SMoaIoicxVG8snbQuRBcjJr135PRLjhfM/HsogFLdwa82H7Fjg71SIqOpbde3575XlDD4dx4ULMiweKHEmwFDJbNu/I7xIU1aF9a7p1b8fevQe4dy+J8uVtFZlXvmT5aiRYCrAGjd7Fs6871atWJiUtneMnTrJkyRru3E7Ua555cydotXL48stVfP/9Ts3txo3eY/oMf34/EErTxq7ExV8h/tJlWrg1Ie7SFfw/n87du/d0rql4CWvGjPGhgUs9Hqam8Msvh2jdqhnfrtnEju2/aMa936Ix3gP7YGtXloQbtwkO3sIvew/odWy79uzXHIufn/crBUs9p1p8tWi65nZ83BU8PEdojdn78wZ+2LaHOnUcqelYncTEe6xctfGZulu1bsbQoR6UKlGSmItxREXH0bhRfboVki/7yjWWAqpKlUrMnjGOI0eO49Xfj7FjZ1KhvB0TJ4zSe64Fgcvx8hqJl9fIXLu+mZqasmH9dnz9JvLOO9W5FH+Vbt0GUrJ4MT5o01yvmmbPGkeZ0qUYOHg0fXsPJ0OtpkyZklpj2nVoyZgxQ/k2eBP9PvFj/YatjBk9lFatm+l1bI+biivhXGS05nnavTv3l1Pt2rqxedNP+Iwcxx9/hjFhvC8uDZw1+10aODMhwI+167fSqWt/AgNX4OrqpFidbwI5Yymg7ty5y1Cfz7lw/iIAN27c4n/f72T8OF/MzE31WstH10XUYmMvYW6W3Y7yQtRFHiQnk3DjFqVLldS5ptp1alC7dg0GfPIpl+KuArB8+Tp69+qmeRxTExOGD+vPsiVrNQ2pLsdfo4pDRT7q2Yn9v4bofGxKSk1J06w6kJR0P9dxmzbv4PDhvwCIPBeD49tVce/anmNHwwHo9XFXQo8c46dtewE4fz6anTt/pWuXdnl8BAWHBEsBlZT0D441q7Fg/iQcHOwpYmmBytQYYxMVpiZm+bJImC41OVSyR61Way2qBtntGx6rXNmeYtbWjB49lE8/HaLZrjI24qGCZyB5JTMzU+v23+GnafF+E81th0oV2LpdezWFR49y6klouCRYCqh6TrWYPWscQV99w8RJ80lOTsbt/UZMn/Z5ga/JCBVGRkZaYfIkE9Psv3Zz5y7m3PkorX253OWNY2xcuK8yGEywqFSqF66lo8sY4Ln/KJR+vNzGNGz8HgkJtzSn0wDm5ubPnSuv6VLTxfhLmJgaU6uOI6cjzgNgYmKMyvi/lQ/iLl0hLTUdh6qVtN4aNjUxwchYuWVWcqPL7/d5VE/VWKdODeKfWH8pNvYyTk7vaI0xNdNuSm7oDCJWX0eX/if5+Xnz6/7N1HOunWc1RUbFYmtTlsZNXbAuaoVrw3oM8e4LgJmZfv8f6LJygC50qenMqQtERJxjrP8IXBo44/h2VQIC/LQeJyU5hW9Wb6Sne0e8+vXE3t6OmrWqsyBoMiNHDNTr2PSly+/3Rdzd2/Nu/brYV7Jj8BAPnJ1q8cPWXZr9mzZvp/57Tgwe4kH1ag60bNUE9+6F5/oKGMgZy+vq0v9Yeno66tR01I8y8qym/b+GUL58OT4bNYTixYsRFR3Ljp37GDiwNxXty5OYmPTc43jSi1YO0JWuNY0dO5PP/Ycxa/pYklMesn373uyzsifOEjZt2E7i3Xt49nWnf/+PSEq8z+8HQ1n5zQad63kZuvx+AXjOiVPEyfMMGtCbt6tXITHxHlOmLuTYsZOa/ceOnWTK1IUMHerBxz07c/5CNH8dPYnzU2cxhkyaab/BmjVrwPgA3xz3bdu+h2XL1r7mirI9/a6VnZ0Nmzcvw3fUJE6EReg0h9KrC+hr4oRRlCpdAj+/SVrb9/68gZXfbND6HFBOnn4OAgJ8sbUty/DhAXlSb0FjEGcshVXYsZMMGJjz51oeJD98zdX8Z9HXMwgNDWPfvoNYW1vjM6wfly5d48zp8zrPcf/+g1yPTZ2RmeP2V1WhQjmMjFTUqFkdN7dGLF323UvN06iJC4MG9mLRomASrt+kfgMnWrVuyvwFyxSuuOCSYHmDpaSmcvXq81/a5Yf585YxYFAvevfqSpo6nfDw08yauYi01HSd58iP1QVmzwrAvqIdN2/dZt2GrWzduvul5vnryHGqVqnI52N8KPtWaa5eS2DhlyvZvXO/whUXXPJSSAihOIN4V0gIUbBIsAghFCfBIoRQnASLEEJxEixCCMVJsAghFCfBIoRQnARLIWKIXfqLWlkx6tPB7Ni5hj2717EwaDKONaq88rzSpf/VSLAUIobYpX/mnLHZ36AeO5thwwNIvJNEUOBU3ipb+pXmDT0cxo6d+xSqsvCRT96KN1aNGtVYuXIe/fuPIiYmDsj+8t+eXev56utV/Pjj3udPIPKMfFeoAJMu/c93N/EekybPJy7ukmabOj2DDLUaY1NjvZ4jkC79SpKXQgWUdOl/sZs3bvPb/j/IzPyvA1/rD5pjZm5O6OEwned5TLr0K0fOWAoo6dKvP/tKdvj5DST4u81ax6wr6dKvHAmWAkq69OundOkSzJszgbCwCNYE/+/lDlBH0qX/xSRYCijp0q+7IkWLMHfeBK5dT2D61CD9J8gD0qXfQEiX/rxXELv0m5qYMGvGF2SoMwkImIM6I/c+xI9Jl/68ZxCxKl36n89Qu/QbGRkxfqIfdrY2zJr1NZYWFpQqVULzkxPp0v96GMQZi3Tpfz5D7dJfoaItLVtkX9tYu/arZ/a7ubk/czYoXfpfD/mA3BtMuvTnHenS/2oM4oylsJIu/cqSLv3KkWB5g0mXfmVJl37lyEshIYTiDOJdISFEwSLBIoRQnASLEEJxEixCCMVJsAghFCfBIoRQnASLEEJxEiwKmzd3AiEh2zQ/PXp0zO+SdDJjpj+z54zT+36eXj346utpeVCReJPJJ28VtiBwOZaW2a0EViyfl8/V5L2OHVuxYoXuXxwUhYMEi8J0bQNpCFxcnbCysiIk5Eh+lyIKGAkWPZiamuI9uA9t276PhZk5UdGxrFq9ib+Pn9J7rp49O9GxY2vsbG1ITLrHvn0hfLtqo1Zj6EoOFRgy2IM6dWqiUhlx9nQUK1as02r7WKRoEYYM9qBJo/pYF7fmUvwV1q3fysEDf+pdU5EilowLGIFb04aoMzI5eCCULxetyrUNZufObfj55wP50iZTFGxyjUUPkyZ/iptbQ+bMXsyQof6cOXOB+XMmUKVKJb3m6dKlLYMG9mblyvX08RhGUOBKunRqi6dnD80YlUpF4LxJZGY+ws93En4jJ6HOVBMYNBlLK0vNuM8+G0o959pMmxbEIO/RhB45zrSpY6hdt4bex1fPuTbXr93k/4Zlt59s3boZI4bn3HipVKkSNGniyi5Z1EvkQM5YdFSlSkXcmjdkxPDxhJ/MXklw6dLvsCtfjpq1qnPxYrzOc/119G9OhJ/icvw1AG7dvMPBkCO4uDgTHLwFAGtrK8ralGHJsu80i3HNmbOYli2aYmFmRsq/TaerVq5IRMRZTkacBWD1qk3cvnmH9BTdv0n82IkTp1i9ejMAFy/GY2NThv5eH7Fo8bfPfDO5XfuWnDsbpelqL8STJFh0VLWaA48ePeLU6XNa2yeMn6v3XNcTbtK9R3vGj/PDrrwNJipjzC3MiH2ib2pS0j+sWrURf38f2rVtQXjEGY4dDWfbNu3u78uXr2XceF8cHaty4sQpwk5EsGvX/pe6vpOSqt2C4dTJc1hYmlPOtizxsVe09nXq+AFr/g1BIZ4mL4V0ZGSkX5Pn5/Hq1xMvj56sXLkOd/dBtGvvwU8/PfuSIjh4C717+7D/wGEcHOz56supzJjpj4nJf6v8hf55nJ7ug1m79gfMzc3x/8yHtd99RVmbMq9c5+PG1Kqn+jTWr1+X4sWs+f1g6Cs/hjBMBhMsujSF1rVxdE4hEhMdh0qlotY7jlrbPTzdadrUVbci/9W0iQt/hB4jLCxCc+HT3NxMa4zj21UZPMST+/f+Yc+u35g2NYihPl/QvFlD6jrXAqColRWDh3hSxqYUhw4dIShoJb37DMPS0oJOndroVROAsZH2sqQ1alQjPU3NtevaDZc6dW7D3l8O5rqqohAGESyvo0t/TEwch0KO4P/FcOo516ZcubJ4eLrT3+sjbt65oxmnS0f8yMiLuLo6Ua1aZYqXsKZLl7a0beuGmel/S0Q8SH6Au3t7fEd5Y1/JDjs7G1q2apb9D/1Kwr9jkmnaxIWx/iOoWbM6ZW3K0Ky5K8WKWWutZ6yr+vWd+KCNG6amptSoUQ0vzx7s2LVP6/pKyZLFadasATt2yEVbkTuDuMbyurr0T54UiPfgPkyeOhoLCwsuRMYwevQUIs/FaMa8qCN+UtI/LF26FgtLc778aiomKhPCTpxk796DtG7VDFMTE9QZGVy9egM/34kMGtiHpYtmY2piTPTFeMZ8MV3rszKjRk9m8KC+zJjuT7Fi1lxPuMHiJcGapUv1cfx4BM2buzLaz5tMHvHrr4dZvChYa8yH7VsSeeGi5oKyEDmR1pQGTulu9+06tOT6lRuad8aEyIkEi4EzMjLCzq5sjvvUGZncvHH7NVckCgODeCkkcpcf3e6FMIiLt0KIgkWCRQihOAkWIYTiJFiEEIqTYBFCKE6CRQihOAkWIYTiJFiEEIqTYCmgevToyN6flW1SXdTKih0719C+YytF5y0obG1taN+upSJz+QzrR1DQFEXmKozkk7eFyIPkZNau/Z6IcMP5no9lEQtauDXmw/YtcHaqRVR0LLv3/PbK84YeDuPChZgXDxQ5kmApZLZs3pHfJSiqQ/vWdOvejr17D3DvXhLly9sqMq98yfLVSLAUZCojPDy64969A0WKFiEi/CyBgcu5/kTbBF3MmztBq5XDl1+u4vvvd2puN270HtNn+PP7gVCaNnYlLv4K8Zcu08KtCXGXruD/+XTu3r0HQING7+LZ153qVSuTkpbO8RMnWbJkDXduJ2rmK17CmjFjfGjgUo+HqSn88sshWrdqxrdrNrFj+y+ace+3aIz3wD7Y2pUl4cZtgoO38MveA3od2649+zXH4ufn/UrBUs+pFl8tmq65HR93BQ/PEVpj9v68gR+27aFOHUdqOlYnMfEeK1dtfKbuVq2bMXSoB6VKlCTmYhxR0XE0blSfboXky75yjaUAK2JpgWONavgHzOSLsTMpZ/sWs2eP07kT3mMLApfj5TUSL6+RuXZ9MzU1ZcP67fj6TeSdd6pzKf4q3boNpGTxYnzQpjkAVapUYvaMcRw5chyv/n6MHTuTCuXtmDhhlNZcs2eNo0zpUgwcPJq+vYeToVZTpkxJrTHtOrRkzJihfBu8iX6f+LF+w1bGjB5Kq9bN9Dq2x03FlXAuMlrzPO3enfvLqXZt3di86Sd8Ro7jjz/DmDDeF5cGzpr9Lg2cmRDgx9r1W+nUtT+BgStwdXVSrM43gZyxFGBpqelMnRyo6T07a84ili+dg1Odmvytx6m6rouoxcZewtwsu0XmhaiLPEhOJuHGLUqXyg6FO3fuMtTncy6cvwjAjRu3+N/3Oxk/zhczc1PS09TUrlOD2rVrMOCTT7kUdxWA5cvX0btXN83jmJqYMHxYf5YtWatpSHU5/hpVHCryUc9O7P81ROdjU1JqSppm1YGkpPu5jtu0eQeHD/8FQOS5GBzfrop71/YcOxoOQK+PuxJ65Bg/bdsLwPnz0ezc+Stdu7TL4yMoOCRYCrDMzExNqACcOxOFOiODipUr6BUsSklK+gfHmtVYMH8SDg72FLG0QGVqjLGJClMTM9LT1DhUsketVmstqgbZ7Rseq1zZnmLW1owePZRPPx2i2a4yNuKhgmcgeSUzM1Pr9t/hp2nxfhPNbYdKFdi6XXs1hUePcupJaLgkWN4gWVlZZKoz9X4ppJR6TrWYPSt7MbOJk+aTnJyM2/uNmD7tc61xRqgwMjLSCpMnmZhm/7WbO3cx585Hae3L5S5vHGPjwn2VwWCCRaVSvXAtHV3GAM/9R6H04z1vzNMB4uBgj4WlOXHxV3Icn9caNn6PhIRbmlN8AHNzc60xF+MvYWJqTK06jpyOOA+AiYkxKuP/Vj6Iu3SFtNR0HKpW0npr2NTEBCNj5ZZZyY0uv9/nUT1VY506NYh/Yk2o2NjLODm9NO3yaAAABTZJREFUozXG1MyUwsQgYvV1dOl/kp+fN7/u30w959p5WpOFpTnDhn9CkaJFeKtsaUaNHkJ0dBzhf59+7jE8TZeVA3QRGRWLrU1ZGjd1wbqoFa4N6zHEuy8AZmbZ/0edOXWBiIhzjPUfgUsDZxzfrkpAgJ/W46Qkp/DN6o30dO+IV7+e2NvbUbNWdRYETWbkiJyXdFWKLr/fF3F3b8+79etiX8mOwUM8cHaqxQ9bd2n2b9q8nfrvOTF4iAfVqznQslUT3LsXnusrYCBnLK+rS/9j6enpqFPTUT/KyHWMEjXdunmHrEePWL92EUWtihAefoZpUxfq/b/ti1YO0NX+X0MoX74cn40aQvHixYiKjmXHzn0MHNibivblSUxMAmDs2Jl87j+MWdPHkpzykO3b92aflT1R96YN20m8ew/Pvu707/8RSYn3+f1gKCu/UfbTxk/T5fcLwHNOnCJOnmfQgN68Xb0KiYn3mDJ1IceOndTsP3bsJFOmLmToUA8+7tmZ8xei+evoSZyfOosxZNJM+w3WrFkDxgf45rhv2/Y9LFu29jVXlO3xO0SP2dnZsHnzMnxHTeJEWIROcyi9uoC+Jk4YRanSJfDzm6S1fe/PG1j5zQatzwHl5OnnICDAF1vbsgwfHpAn9RY0BnHGUliFHTvJgIGjctz3IPnha67mP4u+nkFoaBj79h3E2toan2H9uHTpGmdOn9d5jvv3H+R6bOqMzBy3v6oKFcphZKSiRs3quLk1Yumy715qnkZNXBg0sBeLFgWTcP0m9Rs40ap1U+YvWKZwxQWXBMsbLCU1latXn//SLj/Mn7eMAYN60btXV9LU6YSHn2bWzEVaKyq+SH6sLjB7VgD2Fe24ees26zZsZevW3S81z19HjlO1SkU+H+ND2bdKc/VaAgu/XMnunfsVrrjgkpdCQgjFGcS7QkKIgkWCRQihOAkWIYTiJFiEEIqTYBFCKE6CRQihOAkWIYTiJFgKKOnSr5uiVlaM+nQwO3auYc/udSwMmoxjjSqvPK906X81EiyFiCF26Z85Z2z2N6jHzmbY8AAS7yQRFDiVt8qWfqV5Qw+HsWPnPoWqLHwkWAqZLZt3cOVKQn6XoYgaNapRz6kW8+YtJeLUOS5ejGf23EWYmZnRuFH9V5o7/OQZTdtMoT/5rlBBJl36n+tu4j0mTZ5PXNwlzTZ1egYZajXGpsZ6PUcgXfqVJGcsBZh06X++mzdu89v+P8jM/K8DX+sPmmNmbk7o4TCd53lMuvQrR85YCjDp0q8f+0p2+PkNJPi7zVrHrCvp0q8cCZYCTLr066506RLMmzOBsLAI1gT/7+UOUEfSpf/FJFjeINKlP2dFihZh7rwJXLuewPSpQfpPkAekS7+BkC79ea8gduk3NTFh1owvyFBnEhAwR+sMLzfSpT/vGUSsSpf+5zPULv1GRkaMn+iHna0Ns2Z9jaWFBaVKldD85ES69L8eBnHGIl36n89Qu/RXqGhLyxbZ1zbWrv3qmf1ubu7PnA1Kl/7XQ1pTvsGkS3/ekS79r8YgzlgKK+nSryzp0q8cCZY3mHTpV5Z06VeOvBQSQijOIN4VEkIULBIsQgjFSbAIIRQnwSKEUJwEixBCcRIsQgjFSbAIIRQnwSKEUJwEixBCcRIsQgjFSbAIIRQnwSKEUJwEixBCcRIsQgjFSbAIIRQnwSKEUJwEixBCcRIsQgjFSbAIIRQnwSKEUJwEixBCcRIsQgjFSbAIIRQnwSKEUJwEixBCcRIsQgjFSbAIIRQnwSKEUNz/A7hYapBDL0B2AAAAAElFTkSuQmCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OzXE2Ell0RBk"
   },
   "outputs": [],
   "source": [
    "# Dictionary to map classes.\n",
    "classes = { \n",
    "    0:'Speed limit (20km/h)',\n",
    "    1:'Speed limit (30km/h)', \n",
    "    2:'Speed limit (50km/h)', \n",
    "    3:'Speed limit (60km/h)', \n",
    "    4:'Speed limit (70km/h)', \n",
    "    5:'Speed limit (80km/h)', \n",
    "    6:'End of speed limit (80km/h)', \n",
    "    7:'Speed limit (100km/h)', \n",
    "    8:'Speed limit (120km/h)', \n",
    "    9:'No passing', \n",
    "    10:'No passing veh over 3.5 tons', \n",
    "    11:'Right-of-way at intersection', \n",
    "    12:'Priority road', \n",
    "    13:'Yield', \n",
    "    14:'Stop', \n",
    "    15:'No vehicles', \n",
    "    16:'Veh > 3.5 tons prohibited', \n",
    "    17:'No entry', \n",
    "    18:'General caution', \n",
    "    19:'Dangerous curve left', \n",
    "    20:'Dangerous curve right', \n",
    "    21:'Double curve', \n",
    "    22:'Bumpy road', \n",
    "    23:'Slippery road', \n",
    "    24:'Road narrows on the right', \n",
    "    25:'Road work', \n",
    "    26:'Traffic signals', \n",
    "    27:'Pedestrians', \n",
    "    28:'Children crossing', \n",
    "    29:'Bicycles crossing', \n",
    "    30:'Beware of ice/snow',\n",
    "    31:'Wild animals crossing', \n",
    "    32:'End speed + passing limits', \n",
    "    33:'Turn right ahead', \n",
    "    34:'Turn left ahead', \n",
    "    35:'Ahead only', \n",
    "    36:'Go straight or right', \n",
    "    37:'Go straight or left', \n",
    "    38:'Keep right', \n",
    "    39:'Keep left', \n",
    "    40:'Roundabout mandatory', \n",
    "    41:'End of no passing', \n",
    "    42:'End no passing veh > 3.5 tons'\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vyhgm5Mu8mY"
   },
   "source": [
    "## 1. Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RDTWhXC8W2GP"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZLEpUUtwoMk"
   },
   "source": [
    "- Initializing some useful variables and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yGIBSV4SVvj3"
   },
   "outputs": [],
   "source": [
    "# input_path = \"/content/drive/MyDrive/Smit/kaggle\"\n",
    "# train_path = \"/content/drive/MyDrive/Smit/kaggle/Train\"\n",
    "# test_path = \"/content/drive/MyDrive/Smit/kaggle/Test\"\n",
    "input_path = \"./data/archive/\"\n",
    "train_path = \"./data/archive/Train\"\n",
    "test_path = \"./data/archive/Test\"\n",
    "\n",
    "# new_test_path = \"/content/drive/MyDrive/Smit/kaggle/New_Test\"\n",
    "\n",
    "image_data = []\n",
    "image_labels = []\n",
    "\n",
    "# Number of total classes\n",
    "total_classes = 43\n",
    "\n",
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Dimensions of our images\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaNayEiYrnMF"
   },
   "source": [
    "## Making Test Folder like Train for our convenience ( Optional )\n",
    "- Avoid this step for time's sake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "FLo1R4I7W4IL",
    "outputId": "78b05c3f-4242-4935-fad7-a34aa22e55a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>Test/00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Test/00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>Test/00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>Test/00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>Test/00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
       "0     53      54       6       5      48      49       16  Test/00000.png\n",
       "1     42      45       5       5      36      40        1  Test/00001.png\n",
       "2     48      52       6       6      43      47       38  Test/00002.png\n",
       "3     27      29       5       5      22      24       33  Test/00003.png\n",
       "4     60      57       5       5      55      52       11  Test/00004.png"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(input_path + \"/Test.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9Ow0XzHYlytz"
   },
   "outputs": [],
   "source": [
    "# labels = df['ClassId'].values\n",
    "# img = df['Path'].values\n",
    "# print(len(labels), img)\n",
    "# if os.path.exists(new_test_path) is False:\n",
    "#   os.mkdir(new_test_path)\n",
    "# for i in range(len(labels)):\n",
    "#   if os.path.exists(new_test_path + \"/\" + str(labels[i])) is False:\n",
    "#     os.mkdir(new_test_path + \"/\" + str(labels[i]))\n",
    "#   src_path = input_path + \"/\" + img[i]\n",
    "#   des_path = new_test_path + \"/\" + str(labels[i]) + \"/\" + img[i].split(\"/\")[1]\n",
    "#   try:\n",
    "#     shutil.copy(src_path, des_path)\n",
    "#     print(\"Success\")\n",
    "#   except:\n",
    "#     print(f\"Can't Copy from {src_path} to {des_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDXmakMXmLSN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcEjWn0fyfB5"
   },
   "source": [
    "## Image preprocessing and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMXFDVaPzm0u"
   },
   "source": [
    "### Spliting into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Z4VEQcOiyib7"
   },
   "outputs": [],
   "source": [
    "# train_data_gen = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     train_path,\n",
    "#     validation_split = 0.2,\n",
    "#     subset = \"training\",\n",
    "#     seed = 123,\n",
    "#     image_size = (height, width),\n",
    "#     batch_size = batch_size\n",
    "# )\n",
    "# val_data_gen = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     train_path,\n",
    "#     validation_split = 0.2,\n",
    "#     subset = \"validation\",\n",
    "#     seed = 123,\n",
    "#     image_size = (height, width),\n",
    "#     batch_size = batch_size\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5Gx9qTv8cKt"
   },
   "source": [
    "### Another method of doing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TYmOBZA5zXK_"
   },
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GvqLPo1Q7HLc",
    "outputId": "79ced076-f3f7-43a3-b6c2-75e5741622ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31368 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = datagen.flow_from_directory(train_path,\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = batch_size,\n",
    "                                            subset = \"training\",\n",
    "                                            class_mode='categorical',\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2ehWtQa7byz",
    "outputId": "9f903f24-4d77-44e0-a8bf-b561c838f69f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7841 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = datagen.flow_from_directory(train_path,\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = batch_size,\n",
    "                                            subset = \"validation\",\n",
    "                                            class_mode='categorical',\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WJOpnP78m64"
   },
   "source": [
    "## Creating model architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YmAV_rKc45nx"
   },
   "outputs": [],
   "source": [
    "def my_model():\n",
    "    input_ = tf.keras.layers.Input((height, width, channels))\n",
    "    net = tf.keras.layers.Conv2D(filters=18, kernel_size=(5,5), strides=1, activation=\"relu\")(input_)\n",
    "    net = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)(net)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    \n",
    "    net = tf.keras.layers.Conv2D(filters=36, kernel_size=(5,5), strides=1, activation=\"relu\",\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(0.01), bias_regularizer=tf.keras.regularizers.l2(0.01))(net)\n",
    "    net = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)(net)\n",
    "    \n",
    "    net = tf.keras.layers.Conv2D(filters=36, kernel_size=(5,5), activation=\"relu\")(net)\n",
    "    net = tf.keras.layers.MaxPooling2D(pool_size=(1, 1))(net)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    \n",
    "    net = tf.keras.layers.Flatten()(net)\n",
    "    net = tf.keras.layers.Dense(72, activation= 'relu',\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(0.01), bias_regularizer=tf.keras.regularizers.l2(0.01))(net)\n",
    "    out = tf.keras.layers.Dense(total_classes, activation='softmax')(net)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[input_], outputs=[out])\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy, \n",
    "                  optimizer=tf.keras.optimizers.Adam(lr=0.009), \n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    tf.keras.utils.plot_model(model, to_file='./model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EuLj_lWu_HEs",
    "outputId": "c94252d0-10d8-4bb4-f3ff-db601c6cdbca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 18)        1368      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 18)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 18)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 36)        16236     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 36)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 1, 36)          32436     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 36)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 36)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 72)                2664      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43)                3139      \n",
      "=================================================================\n",
      "Total params: 55,843\n",
      "Trainable params: 55,843\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = my_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqvIEiAKAJ7Y"
   },
   "source": [
    "### Defining Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-toQrJdA_KoE"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches certain limit\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('val_accuracy')>0.95):\n",
    "          print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "          self.model.stop_training = True\n",
    "        \n",
    "reduceLROnPlat = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.95,\n",
    "        patience=2,\n",
    "        verbose=1,\n",
    "        mode='min',\n",
    "        min_delta=0.0001,\n",
    "        cooldown=2,\n",
    "        min_lr=1e-5\n",
    ")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"./model_best.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "    save_weights_only=False, mode='auto', save_freq='epoch'\n",
    ")\n",
    "\n",
    "my_callback = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQ6Q_pJPE47q",
    "outputId": "44e096a8-f7af-4e8b-bad3-d1f4fb067451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "981/981 [==============================] - 359s 364ms/step - loss: 2.2765 - accuracy: 0.3443 - val_loss: 1.7878 - val_accuracy: 0.4904\n",
      "Epoch 2/20\n",
      "981/981 [==============================] - 35s 36ms/step - loss: 1.7563 - accuracy: 0.4862 - val_loss: 1.5545 - val_accuracy: 0.5633\n",
      "Epoch 3/20\n",
      "981/981 [==============================] - 22s 23ms/step - loss: 1.6437 - accuracy: 0.5300 - val_loss: 1.4504 - val_accuracy: 0.5633\n",
      "Epoch 4/20\n",
      "981/981 [==============================] - 27s 27ms/step - loss: 1.5082 - accuracy: 0.5648 - val_loss: 1.2563 - val_accuracy: 0.6636\n",
      "Epoch 5/20\n",
      "981/981 [==============================] - 27s 27ms/step - loss: 1.4677 - accuracy: 0.5845 - val_loss: 1.2614 - val_accuracy: 0.6809\n",
      "Epoch 6/20\n",
      "981/981 [==============================] - 28s 28ms/step - loss: 1.4249 - accuracy: 0.6016 - val_loss: 1.3530 - val_accuracy: 0.6184\n",
      "Epoch 7/20\n",
      "981/981 [==============================] - 28s 28ms/step - loss: 1.3878 - accuracy: 0.6105 - val_loss: 1.2276 - val_accuracy: 0.6766\n",
      "Epoch 8/20\n",
      "981/981 [==============================] - 28s 28ms/step - loss: 1.3751 - accuracy: 0.6118 - val_loss: 1.2313 - val_accuracy: 0.6846\n",
      "Epoch 9/20\n",
      "981/981 [==============================] - 28s 28ms/step - loss: 1.3463 - accuracy: 0.6225 - val_loss: 1.2594 - val_accuracy: 0.6634\n",
      "Epoch 10/20\n",
      "981/981 [==============================] - 28s 28ms/step - loss: 1.3381 - accuracy: 0.6211 - val_loss: 1.1754 - val_accuracy: 0.6977\n",
      "Epoch 11/20\n",
      "981/981 [==============================] - 28s 28ms/step - loss: 1.3491 - accuracy: 0.6169 - val_loss: 1.2677 - val_accuracy: 0.6535\n",
      "Epoch 12/20\n",
      "981/981 [==============================] - 28s 28ms/step - loss: 1.3336 - accuracy: 0.6269 - val_loss: 1.1602 - val_accuracy: 0.6794\n",
      "Epoch 13/20\n",
      "981/981 [==============================] - 28s 28ms/step - loss: 1.3071 - accuracy: 0.6325 - val_loss: 1.1144 - val_accuracy: 0.7063\n",
      "Epoch 14/20\n",
      "981/981 [==============================] - 28s 28ms/step - loss: 1.2923 - accuracy: 0.6361 - val_loss: 1.1104 - val_accuracy: 0.7113\n",
      "Epoch 15/20\n",
      "981/981 [==============================] - 28s 28ms/step - loss: 1.3073 - accuracy: 0.6343 - val_loss: 1.1592 - val_accuracy: 0.6967\n",
      "Epoch 16/20\n",
      "981/981 [==============================] - 29s 29ms/step - loss: 1.3064 - accuracy: 0.6378 - val_loss: 1.1153 - val_accuracy: 0.7060\n",
      "Epoch 17/20\n",
      "981/981 [==============================] - 29s 30ms/step - loss: 1.2811 - accuracy: 0.6448 - val_loss: 1.0898 - val_accuracy: 0.7166\n",
      "Epoch 18/20\n",
      "981/981 [==============================] - 28s 29ms/step - loss: 1.2733 - accuracy: 0.6434 - val_loss: 1.2346 - val_accuracy: 0.6956\n",
      "Epoch 19/20\n",
      "981/981 [==============================] - 28s 29ms/step - loss: 1.2789 - accuracy: 0.6415 - val_loss: 1.0828 - val_accuracy: 0.7036\n",
      "Epoch 20/20\n",
      "981/981 [==============================] - 28s 29ms/step - loss: 1.2922 - accuracy: 0.6404 - val_loss: 1.1867 - val_accuracy: 0.6902\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_datagen,\n",
    "                               epochs = 20,\n",
    "                               verbose = 1,\n",
    "                               validation_data = val_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZM--i3nGFJ3K"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>Test/00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Test/00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>Test/00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>Test/00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>Test/00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
       "0     53      54       6       5      48      49       16  Test/00000.png\n",
       "1     42      45       5       5      36      40        1  Test/00001.png\n",
       "2     48      52       6       6      43      47       38  Test/00002.png\n",
       "3     27      29       5       5      22      24       33  Test/00003.png\n",
       "4     60      57       5       5      55      52       11  Test/00004.png"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/archive/Test.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "0.046\n"
     ]
    }
   ],
   "source": [
    "labels = df['ClassId'].values\n",
    "path = df['Path'].values\n",
    "final_res = []\n",
    "count = 0\n",
    "correct = 0\n",
    "for img in input_path + path:\n",
    "    if count == 500:\n",
    "        break\n",
    "    img1 = tf.keras.preprocessing.image.load_img(img, target_size=(32, 32))\n",
    "    test_img = tf.keras.preprocessing.image.img_to_array(img1, data_format=\"channels_last\")/255\n",
    "    test_img = np.expand_dims(test_img, axis=0)\n",
    "    scores = model.predict(test_img)\n",
    "    preds = np.argmax(scores, axis = 1)\n",
    "    final_res.append(preds)\n",
    "    if preds == labels[count]:\n",
    "        correct += 1\n",
    "        print(correct)\n",
    "    count += 1\n",
    "\n",
    "print(accuracy_score(labels[:500], final_res, normalize = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.112669706344604% probability of End no passing veh > 3.5 tons\n"
     ]
    }
   ],
   "source": [
    "img = \"./data/archive/test/00497.png\"\n",
    "def get_output(img):\n",
    "    img1 = tf.keras.preprocessing.image.load_img(img, target_size=(32, 32), interpolation='nearest')\n",
    "    test_img = tf.keras.preprocessing.image.img_to_array(img1, data_format=\"channels_last\")/255\n",
    "    test_img = np.expand_dims(test_img, axis=0)\n",
    "    scores = model.predict(test_img)\n",
    "    prob = np.max(scores, axis = 1)\n",
    "    preds = np.argmax(scores, axis = 1)\n",
    "    print(f\"{prob[0] * 100}% probability of {classes[preds[0]]}\")\n",
    "get_output(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1123ynKEuvVl",
    "LaNayEiYrnMF"
   ],
   "name": "Recognizing_Traffic_Signs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
